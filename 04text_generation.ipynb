{"cells":[{"cell_type":"markdown","metadata":{"id":"ovpZyIhNIgoq"},"source":["PRACTICAL 4\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yG_n40gFzf9s"},"outputs":[],"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pD_55cOxLkAb","executionInfo":{"status":"ok","timestamp":1653065739848,"user_tz":-330,"elapsed":44,"user":{"displayName":"","userId":""}},"outputId":"6fa7b94a-6478-4f51-98fb-b9f4898ea9a7","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n","1130496/1115394 [==============================] - 0s 0us/step\n"]}],"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aavnuByVymwK","executionInfo":{"status":"ok","timestamp":1653065739849,"user_tz":-330,"elapsed":25,"user":{"displayName":"","userId":""}},"outputId":"20e8d6dd-5add-4af0-9990-92a8d7449597","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 1115394 characters\n"]}],"source":["# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Duhg9NrUymwO","executionInfo":{"status":"ok","timestamp":1653065739850,"user_tz":-330,"elapsed":18,"user":{"displayName":"","userId":""}},"outputId":"87b94b93-32db-4981-d89e-ca4600d263f9","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"]}],"source":["# Take a look at the first 250 characters in text\n","print(text[:250])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlCgQBRVymwR","executionInfo":{"status":"ok","timestamp":1653065741217,"user_tz":-330,"elapsed":1380,"user":{"displayName":"","userId":""}},"outputId":"dbeeb8b5-99eb-4130-f39e-a6f4b1d24e68","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["65 unique characters\n"]}],"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a86OoYtO01go","executionInfo":{"status":"ok","timestamp":1653065744417,"user_tz":-330,"elapsed":452,"user":{"displayName":"","userId":""}},"outputId":"8794fba1-ffae-4729-a53c-5f32431154ca","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"metadata":{},"execution_count":7}],"source":["example_texts = ['abcdefg', 'xyz']\n","\n","chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n","chars"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GMlCe3qzaL9"},"outputs":[],"source":["ids_from_chars = tf.keras.layers.StringLookup(\n","    vocabulary=list(vocab), mask_token=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLv5Q_2TC2pc","executionInfo":{"status":"ok","timestamp":1653065746173,"user_tz":-330,"elapsed":66,"user":{"displayName":"","userId":""}},"outputId":"f0f64276-845c-49ff-db58-78a5cc612543","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"]},"metadata":{},"execution_count":9}],"source":["ids = ids_from_chars(chars)\n","ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wd2m3mqkDjRj"},"outputs":[],"source":["chars_from_ids = tf.keras.layers.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2GCh0ySD44s","executionInfo":{"status":"ok","timestamp":1653065746173,"user_tz":-330,"elapsed":55,"user":{"displayName":"","userId":""}},"outputId":"b914c0b0-326f-487e-a2fd-4f1fc6ffa96e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"metadata":{},"execution_count":11}],"source":["chars = chars_from_ids(ids)\n","chars"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxYI-PeltqKP","executionInfo":{"status":"ok","timestamp":1653065746174,"user_tz":-330,"elapsed":51,"user":{"displayName":"","userId":""}},"outputId":"bb985359-b19f-4cd9-864d-2af09f592b8d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"metadata":{},"execution_count":12}],"source":["tf.strings.reduce_join(chars, axis=-1).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5apvBDn9Ind"},"outputs":[],"source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UopbsKi88tm5","executionInfo":{"status":"ok","timestamp":1653065746175,"user_tz":-330,"elapsed":46,"user":{"displayName":"","userId":""}},"outputId":"f5230b33-4b28-4bf3-e8b7-8ced7686b83d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"metadata":{},"execution_count":14}],"source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmxrYDCTy-eL"},"outputs":[],"source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjH5v45-yqqH","executionInfo":{"status":"ok","timestamp":1653065746176,"user_tz":-330,"elapsed":40,"user":{"displayName":"","userId":""}},"outputId":"3a3d19db-316e-4516-ba32-f7b3a5d85931","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}],"source":["for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-G2oaTxy6km"},"outputs":[],"source":["seq_length = 100\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpdjRO2CzOfZ","executionInfo":{"status":"ok","timestamp":1653065746176,"user_tz":-330,"elapsed":35,"user":{"displayName":"","userId":""}},"outputId":"25042983-bbf4-44b1-a28c-ddcfc5b3e318","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n"," b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n"," b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n"," b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n"," b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n"," b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n"," b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n"," b'o' b'u' b' '], shape=(101,), dtype=string)\n"]}],"source":["sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QO32cMWu4a06","executionInfo":{"status":"ok","timestamp":1653065746176,"user_tz":-330,"elapsed":30,"user":{"displayName":"","userId":""}},"outputId":"5fab1dd6-fb59-4f7c-8b57-654ed4a22cb6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}],"source":["for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NGu-FkO_kYU"},"outputs":[],"source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxbDTJTw5u_P","executionInfo":{"status":"ok","timestamp":1653065746177,"user_tz":-330,"elapsed":26,"user":{"displayName":"","userId":""}},"outputId":"324ae142-584d-47c8-fb42-f4a74e9f2e8a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n"," ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"]},"metadata":{},"execution_count":21}],"source":["split_input_target(list(\"Tensorflow\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9iKPXkw5xwa"},"outputs":[],"source":["dataset = sequences.map(split_input_target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNbw-iR0ymwj","executionInfo":{"status":"ok","timestamp":1653065746177,"user_tz":-330,"elapsed":21,"user":{"displayName":"","userId":""}},"outputId":"c9b2cf7e-a4b2-4c31-dfcc-58e5c789274f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}],"source":["for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2pGotuNzf-S","executionInfo":{"status":"ok","timestamp":1653065746178,"user_tz":-330,"elapsed":19,"user":{"displayName":"","userId":""}},"outputId":"0340e9f1-8462-4c0b-b49b-f35d25d54849","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":24}],"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHT8cLh7EAsg"},"outputs":[],"source":["# Length of the vocabulary in StringLookup Layer\n","vocab_size = len(ids_from_chars.get_vocabulary())\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wj8HQ2w8z4iO"},"outputs":[],"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IX58Xj9z47Aw"},"outputs":[],"source":["model = MyModel(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-_70kKAPrPU","executionInfo":{"status":"ok","timestamp":1653065752834,"user_tz":-330,"elapsed":6670,"user":{"displayName":"","userId":""}},"outputId":"5b15e579-e39d-42fd-afd9-550a90788291","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPGmAAXmVLGC","executionInfo":{"status":"ok","timestamp":1653065752835,"user_tz":-330,"elapsed":51,"user":{"displayName":"","userId":""}},"outputId":"3afe0419-d694-4a52-ed3b-d87903af9611","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  16896     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4,022,850\n","Trainable params: 4,022,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4V4MfFg0RQJg"},"outputs":[],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqFMUQc_UFgM","executionInfo":{"status":"ok","timestamp":1653065754520,"user_tz":-330,"elapsed":54,"user":{"displayName":"","userId":""}},"outputId":"edfd1377-afcc-45ca-8def-ba0d2131e019","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10, 43, 47,  3, 11, 25, 20, 52, 31, 28, 34, 31, 47, 44, 56,  5, 24,\n","       60, 31, 49,  5, 31, 25, 47, 12, 64,  3, 61, 18, 20, 15, 13, 23, 33,\n","       17, 40, 32, 44,  0, 51, 65, 18, 61, 62, 21, 60, 22, 11, 32, 59, 48,\n","        3, 44, 22,  8, 34, 55,  7, 63, 44, 25, 25, 23,  8, 34, 65, 53,  2,\n","       26, 36, 47, 63,  7, 15, 33, 43, 34, 11, 64, 63, 13, 26, 48,  7, 14,\n","       42, 21, 27, 11, 14, 32, 23, 28, 46, 18,  2, 34, 35, 33, 23])"]},"metadata":{},"execution_count":31}],"source":["sampled_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWcFwPwLSo05","executionInfo":{"status":"ok","timestamp":1653065754521,"user_tz":-330,"elapsed":48,"user":{"displayName":"","userId":""}},"outputId":"97fc5277-8b55-4bc4-a195-ae75be204702","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n"," b\"'\\nboth your houses! 'Zounds, a dog, a rat, a mouse, a\\ncat, to scratch a man to death! a braggart, a\\n\"\n","\n","Next Char Predictions:\n"," b'3dh!:LGmROURheq&KuRj&RLh;y!vEGB?JTDaSe[UNK]lzEvwHuI:Sti!eI-Up,xeLLJ-Uzn MWhx,BTdU:yx?Mi,AcHN:ASJOgE UVTJ'\n"]}],"source":["print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOeWdgxNFDXq"},"outputs":[],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HrXTACTdzY-","executionInfo":{"status":"ok","timestamp":1653065754523,"user_tz":-330,"elapsed":36,"user":{"displayName":"","userId":""}},"outputId":"85762790-504c-4cd6-a5f6-9a19e6dee156","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.1890416, shape=(), dtype=float32)\n"]}],"source":["example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", example_batch_mean_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MAJfS5YoFiHf","executionInfo":{"status":"ok","timestamp":1653065754523,"user_tz":-330,"elapsed":27,"user":{"displayName":"","userId":""}},"outputId":"7a759d9e-bd6e-47e0-aa5a-623875292fb0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["65.95955"]},"metadata":{},"execution_count":35}],"source":["tf.exp(example_batch_mean_loss).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDl1_Een6rL0"},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6fWTriUZP-n"},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yGBE2zxMMHs"},"outputs":[],"source":["EPOCHS = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UK-hmKjYVoll","executionInfo":{"status":"ok","timestamp":1653066436920,"user_tz":-330,"elapsed":682415,"user":{"displayName":"","userId":""}},"outputId":"8e81159a-9354-451a-fb52-7e6df620bf0e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","172/172 [==============================] - 26s 126ms/step - loss: 2.7128\n","Epoch 2/20\n","172/172 [==============================] - 24s 126ms/step - loss: 1.9865\n","Epoch 3/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.7045\n","Epoch 4/20\n","172/172 [==============================] - 24s 129ms/step - loss: 1.5428\n","Epoch 5/20\n","172/172 [==============================] - 24s 128ms/step - loss: 1.4439\n","Epoch 6/20\n","172/172 [==============================] - 24s 128ms/step - loss: 1.3768\n","Epoch 7/20\n","172/172 [==============================] - 24s 128ms/step - loss: 1.3231\n","Epoch 8/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.2783\n","Epoch 9/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.2369\n","Epoch 10/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.1977\n","Epoch 11/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.1565\n","Epoch 12/20\n","172/172 [==============================] - 24s 126ms/step - loss: 1.1152\n","Epoch 13/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.0711\n","Epoch 14/20\n","172/172 [==============================] - 24s 127ms/step - loss: 1.0256\n","Epoch 15/20\n","172/172 [==============================] - 24s 127ms/step - loss: 0.9769\n","Epoch 16/20\n","172/172 [==============================] - 24s 127ms/step - loss: 0.9260\n","Epoch 17/20\n","172/172 [==============================] - 24s 127ms/step - loss: 0.8740\n","Epoch 18/20\n","172/172 [==============================] - 24s 128ms/step - loss: 0.8220\n","Epoch 19/20\n","172/172 [==============================] - 24s 127ms/step - loss: 0.7701\n","Epoch 20/20\n","172/172 [==============================] - 24s 127ms/step - loss: 0.7230\n"]}],"source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSBU1tHmlUSs"},"outputs":[],"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqMOuDutnOxK"},"outputs":[],"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ST7PSyk9t1mT","executionInfo":{"status":"ok","timestamp":1653066442299,"user_tz":-330,"elapsed":5388,"user":{"displayName":"","userId":""}},"outputId":"c8ba14a3-ea57-49dc-f8de-275740b9e75e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\n","This did your greatest bosom to your love;\n","Yet put it not ta'en, but a power her life,\n","Till she had left me here I cut off so take away my person\n","Of noble henceforth for them hence,\n","To call her up, rewards: do not he flattering-death.\n","Throw up thine own couragest, all degree our friends.\n","Cut where the duke shall be so feign;\n","And therefore stand by his wife's son, withow!\n","\n","uf, thou wouldst drink for one so deep to fair,\n","Being cheerly, knee King Henry lour.\n","\n","EDWARD:\n","The curse in being comeness and the sword\n","Unanswer'd head Bianca more in hander\n","forms.\n","\n","KING RICHARD II:\n","We are all up: still through the wall, and now grant me,\n","come hath life-didedier death to let it obey.\n","What's occance, hence, at once?\n","I talk'd it for, and ne'er will I do to;\n","You shall have neighbour one another be their birts?\n","One word that I do prove a straitor when?\n","For welcome home, bend with first, how south\n","to them Richmond; and, standing but a light.\n","And tell the worft: these woes, tame cruel\n","About, or make it flo \n","\n","________________________________________________________________________________\n","\n","Run time: 5.3191447257995605\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkLu7Y8UCMT7","executionInfo":{"status":"ok","timestamp":1653066448793,"user_tz":-330,"elapsed":6503,"user":{"displayName":"","userId":""}},"outputId":"da6c119d-af67-419d-cd80-055878650a74","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b\"ROMEO:\\nThis giving liqeal day, myself have strong,\\nBut often hath deceived the sea inhoot awhile\\nto forwife for my poor good but asheard.\\n\\nQUEEN MARGARET:\\nI thank you,--\\n\\nROMEO:\\nO, do not so: fellow, if once Mow,\\nHave you at forcony with 'et\\nOn him that had not wantoning which he is fruited\\nThe centrous voices; for with a leaven too\\nwhateless up, sometime she promised that she\\nshall make the taps of mine shall piece unthis place.\\nWhat is that cannot be. I will be out,\\nAnd not believed, the people he marr'd her,\\nAnd thou but letters; go, and in weak arms,\\nAnd hide me from forth that again.\\n\\nKING RICHARD III:\\nUp-witness who with an Edward's thum\\nTo your return; and thy best royal self is flower.\\n\\nLADY ANNE:\\nTouch'd him that goes to-day, or two, leave me!\\nMore nor the might am I should not am\\nLew forbid\\nWith one respect I seem by the villain,\\nFor 'ever would have vented them.\\n\\nMAMILLIUS:\\nNo, Warwick, to the sight.\\n\\nLADY ANNE:\\nThe lie when treason, hunts himself.\\n\\nMOPSA:\\nIt is my warriar. Thou a\"\n"," b\"ROMEO:\\nThuse hate obherwity, who ne'er ask me fair,\\nHave I not dead; and happy Bolingbroke to\\nhim:\\nBy heaven forget, to London seem' to our troody.\\n\\nJULIET:\\nI do thee have a figured hands.\\nMy father faith, no doubt. You tall the wall\\nGog inform the trunches' knowledge. Let's be your child.\\n\\nROMEO:\\nNeither, fit to the Tower, of any gain of mine.\\n\\nDUCHESS OF YORK:\\nI weigh'T: bear him thence our shrewded as\\nHot art thou sleep: you have a son fond son\\nMeing for that I again decay: the English kingdom\\nOf home, press forth in Greece, and treacherous,\\nBuckingham'd Richard, wish, a virtuous and\\nTo seat. What is my fancy is return'd,\\nIn thy heirs: but had needs asky\\nas.\\n\\nBRUTUS:\\nAnd this alone, Light, for my shame.\\nDoth get you of your nuins, and eager palt\\nHath promised me for common chamber;\\nThe one for speech and service to their Jesh,\\nThan showeld live England, wretched by the sea\\nWhen it is sorry for means to be king.\\n\\nKING EDWARD IV:\\nBut saw her, thou do there, be there?\\n\\nBUCKINGHAM:\\nHa-dow to \"\n"," b\"ROMEO:\\nThe prettiest Paulposing of the body pitions in\\ncommon people's worth in banishment, or to enjoy\\nThat the signs of her most impeachments from the reach.\\nWhat may beftail his sleep? Would a determined heart will\\nMaich; now the rabbing of ill: I hear the city\\nIf I did disgrace: come, you shall never\\nDo so saff a catch.\\n\\nKING RICHARD II:\\nBut for the instant arties?\\n\\nCOMINIUS:\\nHear me speak.\\n\\nANGELO:\\nWell; I say, give us like a chroniciping.\\n\\nANTONIO:\\nThe lords o' the sea:\\nWho will go what my dear soul is my foot:\\nCame to my tent; and let the event of weathment,\\nStreaming the empty eash of gain or good;\\nAnd so it should not live with silence to her.\\n\\nPOMPEY:\\nI take my leave in triumph, and a heavier.\\n\\nGLOUCESTER:\\nHe hath good men will come against the hair?\\nThe sight of any other did I turne!\\nMaster, haste; and see how he relished his\\nbrother.\\n\\nProvost:\\nGo to: sit deadly beheld for willingly.\\n\\nWARWICK:\\nTrue! I'll be sweet vice awhile: but he\\nI know, in a mother; but that must die to\\nme; y\"\n"," b\"ROMEO:\\nThe measure of the substitute, may it please you, sweet\\nHant in suffering; what your purse is not\\nHath thought as one would swear so fast?\\n\\nBUSHY:\\nDeclinate Mercutio, they are gone?\\n\\nCLARENCE:\\nAlas! it is most justice of your servants,\\nIs that I love myself and death they were,\\nAnd brings them to another of a melancholy\\nAns, that the oxein girl to his eyes\\nAs presently to chide away!\\n\\nKING EDWARD IV:\\nThings have known the any on the crown,\\nAnd with his feering sight as oath as on\\nthe aid. Both laid I won upon; yet if\\nthou not become my life; and if you break,\\nYet welcome talk'd of compups in his high\\nAppear, to give them in. I say she's dead.\\n\\nLARTIUS:\\nO, let her shall be so.\\n\\nCLIFFORD:\\nWhat season say, my Lord Was it your heins,\\nThat full of patricians do with Hereford's intringe\\nAnd spect wooing. A holy diade\\nOf breaking openities?\\nProspections, thou set'st on a Judy ribe?\\n\\nPAULINA:\\nI cannot speak.\\n\\nYORK:\\n'Twill greeten your father's death,\\nO' dost gently and inform your favour:\\nBut\"\n"," b\"ROMEO:\\nYet made you please.\\n\\nQUEEN MARGARET:\\nSo foll it goes to mercy; and 'tis one at firm\\nThat highout tortured sorrows with you.\\n\\nYORK:\\nAs but a little day such in this seven\\nyears and hairy tomorrow? Warwick, wilt thou know,\\nOnce more in men to make my life and hardon.\\n\\nHORTENSIO:\\nMadam, he should have but accordingement King Richard\\nThough cried 'God save his wife's sons,\\nUp wing, will boint your salt musician, and so hait.\\n\\nClown:\\nHe will come on, so many years of his most report,\\nSo long and break and what your voices here.\\n\\nESCALUS:\\nShe hath not rour'd each at the town.\\n\\nLUCIO:\\nI believe it.\\n\\nDUKE VINCENTIO:\\nAre welcome hither hold?\\n\\nLUCIO:\\n\\nISABELLA:\\nYou will not go me so? the like ass\\nmany tricked holy as too late off gentle,\\nAs is as palace Death drops mind one,\\nWho his requition with our senses\\nstraight of his poverons.:\\nPlantagenet doth longer tell me,\\nAway with hers one honour. He prettiest shore\\nIs right no loath the law, no dearer walls,\\nAs York from you as see,\\nAnd all the m\"], shape=(5,), dtype=string) \n","\n","________________________________________________________________________________\n","\n","Run time: 6.169463634490967\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result, '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Grk32H_CzsC","executionInfo":{"status":"ok","timestamp":1653066457981,"user_tz":-330,"elapsed":9270,"user":{"displayName":"","userId":""}},"outputId":"8d59549c-65e8-47f9-97fd-2c6ecc6d2613","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f4f5fe74310>, because it is not built.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: one_step/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: one_step/assets\n"]}],"source":["tf.saved_model.save(one_step_model, 'one_step')\n","one_step_reloaded = tf.saved_model.load('one_step')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Z9bb_wX6Uuu","executionInfo":{"status":"ok","timestamp":1653066458690,"user_tz":-330,"elapsed":716,"user":{"displayName":"","userId":""}},"outputId":"4eab8a49-c777-484f-b946-e1d53c6e3d7c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\n","Good morrow boy! Being caitiff!\n","\n","WARWICK:\n","Unsitting late, lect undo his brother,\n","That I endy Montag\n"]}],"source":["states = None\n","next_char = tf.constant(['ROMEO:'])\n","result = [next_char]\n","\n","for n in range(100):\n","  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0pZ101hjwW0"},"outputs":[],"source":["class CustomTraining(MyModel):\n","  @tf.function\n","  def train_step(self, inputs):\n","      inputs, labels = inputs\n","      with tf.GradientTape() as tape:\n","          predictions = self(inputs, training=True)\n","          loss = self.loss(labels, predictions)\n","      grads = tape.gradient(loss, model.trainable_variables)\n","      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      return {'loss': loss}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XKyWiZ_Lj7w5"},"outputs":[],"source":["model = CustomTraining(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U817KUm7knlm"},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o694aoBPnEi9","executionInfo":{"status":"ok","timestamp":1653066502293,"user_tz":-330,"elapsed":43611,"user":{"displayName":"","userId":""}},"outputId":"b0cb4b06-988a-4cf6-a6bf-452f5f8db92d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["172/172 [==============================] - 26s 126ms/step - loss: 2.7066\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4f38a0f590>"]},"metadata":{},"execution_count":49}],"source":["model.fit(dataset, epochs=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4tSNwymzf-q","executionInfo":{"status":"ok","timestamp":1653066732519,"user_tz":-330,"elapsed":230268,"user":{"displayName":"","userId":""}},"outputId":"31b62453-a677-41ee-b997-d7f7c1f521d0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 2.1841\n","Epoch 1 Batch 50 Loss 2.0907\n","Epoch 1 Batch 100 Loss 1.9664\n","Epoch 1 Batch 150 Loss 1.8555\n","\n","Epoch 1 Loss: 1.9854\n","Time taken for 1 epoch 23.74 sec\n","________________________________________________________________________________\n","Epoch 2 Batch 0 Loss 1.8116\n","Epoch 2 Batch 50 Loss 1.7556\n","Epoch 2 Batch 100 Loss 1.6754\n","Epoch 2 Batch 150 Loss 1.6251\n","\n","Epoch 2 Loss: 1.7055\n","Time taken for 1 epoch 22.79 sec\n","________________________________________________________________________________\n","Epoch 3 Batch 0 Loss 1.5853\n","Epoch 3 Batch 50 Loss 1.5284\n","Epoch 3 Batch 100 Loss 1.5141\n","Epoch 3 Batch 150 Loss 1.4971\n","\n","Epoch 3 Loss: 1.5455\n","Time taken for 1 epoch 22.81 sec\n","________________________________________________________________________________\n","Epoch 4 Batch 0 Loss 1.4475\n","Epoch 4 Batch 50 Loss 1.4685\n","Epoch 4 Batch 100 Loss 1.4012\n","Epoch 4 Batch 150 Loss 1.3998\n","\n","Epoch 4 Loss: 1.4451\n","Time taken for 1 epoch 22.86 sec\n","________________________________________________________________________________\n","Epoch 5 Batch 0 Loss 1.3670\n","Epoch 5 Batch 50 Loss 1.3833\n","Epoch 5 Batch 100 Loss 1.3427\n","Epoch 5 Batch 150 Loss 1.3489\n","\n","Epoch 5 Loss: 1.3781\n","Time taken for 1 epoch 22.99 sec\n","________________________________________________________________________________\n","Epoch 6 Batch 0 Loss 1.3408\n","Epoch 6 Batch 50 Loss 1.3454\n","Epoch 6 Batch 100 Loss 1.3057\n","Epoch 6 Batch 150 Loss 1.3432\n","\n","Epoch 6 Loss: 1.3258\n","Time taken for 1 epoch 22.92 sec\n","________________________________________________________________________________\n","Epoch 7 Batch 0 Loss 1.2540\n","Epoch 7 Batch 50 Loss 1.2907\n","Epoch 7 Batch 100 Loss 1.2888\n","Epoch 7 Batch 150 Loss 1.2521\n","\n","Epoch 7 Loss: 1.2818\n","Time taken for 1 epoch 22.92 sec\n","________________________________________________________________________________\n","Epoch 8 Batch 0 Loss 1.2057\n","Epoch 8 Batch 50 Loss 1.2425\n","Epoch 8 Batch 100 Loss 1.2277\n","Epoch 8 Batch 150 Loss 1.2049\n","\n","Epoch 8 Loss: 1.2405\n","Time taken for 1 epoch 22.96 sec\n","________________________________________________________________________________\n","Epoch 9 Batch 0 Loss 1.1546\n","Epoch 9 Batch 50 Loss 1.2250\n","Epoch 9 Batch 100 Loss 1.2107\n","Epoch 9 Batch 150 Loss 1.2109\n","\n","Epoch 9 Loss: 1.2009\n","Time taken for 1 epoch 22.90 sec\n","________________________________________________________________________________\n","Epoch 10 Batch 0 Loss 1.1305\n","Epoch 10 Batch 50 Loss 1.1572\n","Epoch 10 Batch 100 Loss 1.1654\n","Epoch 10 Batch 150 Loss 1.1872\n","\n","Epoch 10 Loss: 1.1597\n","Time taken for 1 epoch 23.11 sec\n","________________________________________________________________________________\n"]}],"source":["EPOCHS = 10\n","\n","mean = tf.metrics.Mean()\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    mean.reset_states()\n","    for (batch_n, (inp, target)) in enumerate(dataset):\n","        logs = model.train_step([inp, target])\n","        mean.update_state(logs['loss'])\n","\n","        if batch_n % 50 == 0:\n","            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n","            print(template)\n","\n","    # saving (checkpoint) the model every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n","\n","    print()\n","    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n","    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n","    print(\"_\"*80)\n","\n","model.save_weights(checkpoint_prefix.format(epoch=epoch))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"04text_generation.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb","timestamp":1653068214683}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}