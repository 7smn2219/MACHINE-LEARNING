{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03backpropogation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["PRACTICAL 3\n","\n","---\n","\n"],"metadata":{"id":"SL1PWS1wEm9_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYBrwlRq2rOn","outputId":"65dbd758-8c67-4516-e86b-60d11b838970","executionInfo":{"status":"ok","timestamp":1650608244414,"user_tz":-330,"elapsed":6,"user":{"displayName":"swapnil Nangare","userId":"04281520114799692047"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","2\n","2\n","Hidden Layer [{'weights': [0.11517607958476317, 0.2681825006020413, 0.4673963423425349]}, {'weights': [0.833740996638731, 0.5754468783679341, 0.2853131175524055]}]\n","Output Layer [{'weights': [0.1373937049881112, 0.6050857583718962, 0.5990101052493135]}, {'weights': [0.9914511113725891, 0.2402360120314052, 0.2995239915476997]}]\n","[[{'weights': [0.11517607958476317, 0.2681825006020413, 0.4673963423425349]}, {'weights': [0.833740996638731, 0.5754468783679341, 0.2853131175524055]}], [{'weights': [0.1373937049881112, 0.6050857583718962, 0.5990101052493135]}, {'weights': [0.9914511113725891, 0.2402360120314052, 0.2995239915476997]}]]\n","Network [[{'weights': [0.11517607958476317, 0.2681825006020413, 0.4673963423425349]}, {'weights': [0.833740996638731, 0.5754468783679341, 0.2853131175524055]}], [{'weights': [0.1373937049881112, 0.6050857583718962, 0.5990101052493135]}, {'weights': [0.9914511113725891, 0.2402360120314052, 0.2995239915476997]}]]\n","[[{'weights': [0.11517607958476317, 0.2681825006020413, 0.4673963423425349]}, {'weights': [0.833740996638731, 0.5754468783679341, 0.2853131175524055]}], [{'weights': [0.1373937049881112, 0.6050857583718962, 0.5990101052493135]}, {'weights': [0.9914511113725891, 0.2402360120314052, 0.2995239915476997]}]]\n",">epoch=0, lrate=0.500, error=6.335\n",">epoch=1, lrate=0.500, error=5.539\n",">epoch=2, lrate=0.500, error=5.205\n",">epoch=3, lrate=0.500, error=5.079\n",">epoch=4, lrate=0.500, error=4.961\n",">epoch=5, lrate=0.500, error=4.790\n",">epoch=6, lrate=0.500, error=4.562\n",">epoch=7, lrate=0.500, error=4.293\n",">epoch=8, lrate=0.500, error=4.000\n",">epoch=9, lrate=0.500, error=3.695\n",">epoch=10, lrate=0.500, error=3.388\n",">epoch=11, lrate=0.500, error=3.090\n",">epoch=12, lrate=0.500, error=2.810\n",">epoch=13, lrate=0.500, error=2.552\n",">epoch=14, lrate=0.500, error=2.319\n",">epoch=15, lrate=0.500, error=2.110\n",">epoch=16, lrate=0.500, error=1.924\n",">epoch=17, lrate=0.500, error=1.758\n",">epoch=18, lrate=0.500, error=1.612\n",">epoch=19, lrate=0.500, error=1.483\n","[{'weights': [1.3775713149285755, -2.003061229075508, -0.35312152154231213], 'output': 0.9432649082078101, 'delta': -0.010504780928108571}, {'weights': [0.9181632800751891, 0.6970968114652776, 0.3411627732693091], 'output': 0.9999463410439671, 'delta': 2.1120010134239663e-06}]\n","[{'weights': [-2.3251309951985872, 0.4218977561205917, 0.5376606144708534], 'output': 0.236497290797693, 'delta': 0.042703446019783216}, {'weights': [2.517364937366469, -0.5021978362198234, -0.5776244340532232], 'output': 0.7752445029139932, 'delta': -0.03916150201242694}]\n"]}],"source":["# Import Packages\n","from math import exp\n","from random import seed\n","from random import random\n"," \n","# Initialize a network\n","def initialize_network(n_inputs, n_hidden, n_outputs):\n","\tnetwork = list()\n","\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n","\tprint(\"Hidden Layer\",hidden_layer)\n","\tnetwork.append(hidden_layer)\n","\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n","\tprint(\"Output Layer\",output_layer)\n","\tnetwork.append(output_layer)\n","\tprint(network)\n","\treturn network\n"," \n","# Calculate neuron activation for an input\n","def activate(weights, inputs):\n","\tactivation = weights[-1]\n","\tfor i in range(len(weights)-1):\n","\t\tactivation += weights[i] * inputs[i]\n","\treturn activation\n"," \n","# Transfer neuron activation\n","def transfer(activation):\n","\treturn 1.0 / (1.0 + exp(-activation)) # sigmoid function\n"," \n","# Forward propagate input to a network output\n","def forward_propagate(network, row):\n","\tinputs = row\n","\tfor layer in network:\n","\t\tnew_inputs = []\n","\t\tfor neuron in layer:\n","\t\t\tactivation = activate(neuron['weights'], inputs)\n","\t\t\tneuron['output'] = transfer(activation)\n","\t\t\tnew_inputs.append(neuron['output'])\n","\t\tinputs = new_inputs\n","\treturn inputs\n"," \n","# Calculate the derivative of an neuron output\n","def transfer_derivative(output):\n","\treturn output * (1.0 - output)\n"," \n","# Backpropagate error and store in neurons\n","def backward_propagate_error(network, expected):\n","\tfor i in reversed(range(len(network))):\n","\t\tlayer = network[i]\n","\t\terrors = list()\n","\t\tif i != len(network)-1:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\terror = 0.0\n","\t\t\t\tfor neuron in network[i + 1]:\n","\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n","\t\t\t\terrors.append(error)\n","\t\telse:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\tneuron = layer[j]\n","\t\t\t\terrors.append(neuron['output'] - expected[j])\n","\t\tfor j in range(len(layer)):\n","\t\t\tneuron = layer[j]\n","\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n"," \n","# Update network weights with error\n","def update_weights(network, row, l_rate):\n","\tfor i in range(len(network)):\n","\t\tinputs = row[:-1]\n","\t\tif i != 0:\n","\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n","\t\tfor neuron in network[i]:\n","\t\t\tfor j in range(len(inputs)):\n","\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n","\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n"," \n","# Train a network for a fixed number of epochs\n","def train_network(network, train, l_rate, n_epoch, n_outputs):\n","\tfor epoch in range(n_epoch):\n","\t\tsum_error = 0\n","\t\tfor row in train:\n","\t\t\toutputs = forward_propagate(network, row)\n","\t\t\texpected = [0 for i in range(n_outputs)]\n","\t\t\texpected[row[-1]] = 1\n","\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n","\t\t\tbackward_propagate_error(network, expected)\n","\t\t\tupdate_weights(network, row, l_rate)\n","\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n"," \n","# Test training backprop algorithm\n","#seed(1)\n","dataset = [[2.7810836,2.550537003,0],\n","\t[1.465489372,2.362125076,0],\n","\t[3.396561688,4.400293529,0],\n","\t[1.38807019,1.850220317,0],\n","\t[3.06407232,3.005305973,0],\n","\t[7.627531214,2.759262235,1],\n","\t[5.332441248,2.088626775,1],\n","\t[6.922596716,1.77106367,1],\n","\t[8.675418651,-0.242068655,1],\n","\t[7.673756466,3.508563011,1]]\n","print(len(dataset[0])) # total number of columns\n","n_inputs = len(dataset[0]) - 1\n","print(n_inputs)\n","n_outputs = len(set([row[-1] for row in dataset]))\n","print(n_outputs)\n","network = initialize_network(n_inputs, 2, n_outputs)\n","print(\"Network\",network)\n","print(network)\n","train_network(network, dataset, 0.5, 20, n_outputs)\n","for layer in network:\n","\tprint(layer)"]},{"cell_type":"code","source":[""],"metadata":{"id":"LZk6iPjy3mgm"},"execution_count":null,"outputs":[]}]}